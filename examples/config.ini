[DEFAULT]
###
# The DEFAULT section contains configuration items that affect the behaviour
# of the script globally. Global configuration can be referenced from anywhere
# in the configuration file by using the '$' character and the name of the
# configuration item, i.e. $output_path.
#
# Configuration options:
#
#     output_path
#         Full path to the root directory to store script output in. Often the
#         script output will be organized into subdirectories, but output_path
#         represents the top-level directory in the hierarchy, i.e.
#             c:\script_output
#
#     log_path
#         Full path to the directory to store log files in, i.e.
#             $output_path\Logs
#         ALL logs in log_path will be deleted when the script runs.
#
#     log_queries
#         [True/False]
#         Flag to turn on or off the logging of all SQL executed by the script.
#         Logs will be placed in log_path.
#
#     overwrite_working_dbs
#         [True/False]
#         Flag indicating whether or not to delete existing working databases
#         specified by working_db_path in the [databases] configuration section.
#         If False, existing databases will be kept, but individual tables may
#         be replaced at the discretion of each task module.
#
#     overwrite_reporting_tables
#         [True/False]
#         Flag indicating whether or not to drop existing reporting tables
#         specified by queries which make use of the reporting feature. If
#         False, reporting data will be appended to the existing tables.
#
#     logging_config
#         Absolute or relative path from this config file to the MincePy
#         logging config file.
###
output_path                = C:\MincePy
log_path                   = $output_path\Logs
log_queries                = True
overwrite_working_dbs      = True
overwrite_reporting_tables = True
logging_config             = ..\conf\logging.ini

[databases]
###
# This section contains the databases to run each query or data import against.
# Entries can be added or removed freely.
#
# Configuration options:
#
#     enabled
#         [True/False]
#         Flag indicating whether this database should be processed or not.
#
#     original_db_path (MS Access)
#         Path to the original database. This is treated as read-only by the
#         script.
#
#     working_db_path (MS Access)
#         Path to the working copy of the target database. If it does not exist,
#         or if the overwrite_working_dbs flag is set, it will be created by
#         copying the database specified in original_db_path.
#
#     host (server-based databases)
#         IP address or hostname of a database server to connect to.
#
#     db (server-based databases)
#         Database on the specified host to connect to.
#
#     user (server-based databases)
#         Username on the specified host to connect as.
#
#     pwd (server-based databases)
#         Password for the specified user.
#
#     schema (server-based databases) (optional)
#         Optional: the schema to execute queries against.
###
    [[test]]
    enabled          = True
    working_db_path  = $output_path\test.db

[data_imports]
###
# This section allows you to import data from external sources into each
# configured database. By default, the new table is named according to the
# data import (the name enclosed in the [[subsection header]]).
#
# Configuration options:
#
#     order
#         The order that a data import task runs in.
#
#     type (optional)
#         Specifies the type of the file. If this parameter is not provided,
#         MincePy will use the file extension.
#         Valid types:
#             xls   - Excel (2003 or 2010/xlsx)
#             xlsx  - Excel (2003 or 2010/xlsx)
#             csv   - Delimited text
#             mdb   - MS Access (2003 or 2010/accdb)
#             accdb - MS Access (2003 or 2010/accdb)
#             pg    - Postgres
#             db    - SQLite
#
#     file (file-based data sources)
#         Absolute or relative path to a file to import data from.
#
#     host (server-based data sources)
#         Hostname of the database server to connect to.
#
#     db (server-based data sources)
#         The database to connect to.
#
#     schema (server-based data sources) (optional)
#         The schema to execute queries in.
#
#     user (server-based data sources)
#         The user to connect as.
#
#     pwd (server-based data sources)
#         The user's password.
#
#     table (mdb or server-based data sources only)
#         Specifies the table to import, if importing from a database. Mutually
#         exclusive with 'sql'.
#
#     sql (mdb or server-based data sources only)
#         A simple query to import results from, if importing from a database.
#         Mutually exclusive with 'table'.
#
#     columns (optional - csv/xls only)
#         Specifies the column names to use in the output table. If this
#         parameter is not provided, the column names are taken from the first
#         row in the range.
#         The columns list can also contain a single "variable column" - a
#         collection of columns which is not necessarily wholly present in the
#         file, specified as a name followed by one or more columns in
#         parentheses:
#         my_variable_columns(col1, col2, col3)
#
#     worksheet (xls only)
#         Specifies the worksheet to import data from.
#
#     start_cell (xls only)
#         Specifies the top-left cell in the range of data to import.
#
#     end_cell (xls only)
#         Specifies the bottom-right cell in the range of data to import.
#
#     start_line (csv only)
#         The line to start reading from.
#
#     delimiter (csv only) (optional)
#         The delimiter that separates the columns in a delimited file. Defaults
#         to ",". Also accepts the special delimiter "whitespace", which uses
#         any whitespace between values as the delimiter (i.e. a mixture of tabs
#         and spaces, or a varying number of spaces) -- note that this does not
#         work if values contain spaces that are part of the data.
#
#     destination_table (optional)
#         The name of the table to import into. This switches the mode of import
#         from a single table using the data import name to a table with a user-
#         defined name that multiple import tasks can append to.
#
#     import_title_column (optional)
#         Used along with the destination_table option, this adds a column with
#         a user-defined name that holds the name of each data import task to
#         identify the rows that each individual task contributed to a common
#         table.
###
    [[orders]]
    order               = 1
    file                = sample.xls
    start_cell          = D6
    end_cell            = F9
    
    [[office_supplies]]
    order               = 2
    file                = sample.xls
    worksheet           = Sheet2
    start_cell          = I8
    end_cell            = J10
    columns             = item, color
    
    [[foo]]
    order               = 3
    file                = sample.xls
    worksheet           = Sheet3
    
    [[open_ended_foo]]
    order               = 4
    file                = sample.xls
    worksheet           = Sheet3
    start_cell          = D14
    columns             = whee, blah
    
    [[csv_test]]
    order               = 5
    file                = sample.csv
    start_line          = 1
    columns             = col1, col2
    delimiter           = ","

    [[csv_float_test]]
    order               = 6
    file                = sample_floats.csv
    types               = float, float, float
    delimiter           = whitespace
    
    [[null_placeholders]]
    order               = 7
    file                = sample.xls
    worksheet           = Sheet4
    start_cell          = C22
    end_cell            = D25
    null_values         = -,
    db_null             = -1

    [[open_end_row_null_placeholders]]
    order               = 8
    file                = sample.xls
    worksheet           = Sheet4
    start_cell          = C22
    end_cell            = D
    null_values         = -,
    db_null             = -1
    
    [[composite_import_part1]]
    order               = 9
    file                = sample.xls
    worksheet           = Sheet2
    columns             = item, color
    start_cell          = I8
    end_cell            = J8
    destination_table   = composite_import

    [[composite_import_part2]]
    order               = 10
    file                = sample.xls
    worksheet           = Sheet2
    columns             = item, color
    start_cell          = I9
    end_cell            = J9
    destination_table   = composite_import

    [[identifying_composite_import_part1]]
    order               = 11
    file                = sample.csv
    columns             = lhs, rhs
    destination_table   = identifying_composite_import
    import_title_column = import_step

    [[identifying_composite_import_part2]]
    order               = 12
    file                = sample2.csv
    worksheet           = Sheet2
    columns             = lhs, rhs
    destination_table   = identifying_composite_import
    import_title_column = import_step

    [[xlsx_test]]
    order               = 13
    file                = xlsx_test.xlsx
    
    [[mdb_test_1]]
    order               = 14
    file                = mdb_test.mdb
    table               = mdb_import_test_1
    
    [[mdb_accdb_identifying_composite_1]]
    order               = 15
    file                = mdb_test.mdb
    table               = mdb_import_test_1
    destination_table   = mdb_import_test_2
    import_title_column = import_step
    
    [[mdb_accdb_identifying_composite_2]]
    order               = 16
    file                = accdb_test.accdb
    table               = accdb_import_test_1
    destination_table   = mdb_import_test_2
    import_title_column = import_step

[queries]
###
# The query runner is designed to run a set of queries against a number of
# databases with the same schema. Queries run in a specified order, and each
# query must be stored in its own file. Query files can have comments which can
# be indented to any level and can appear at the end of a line:
#
# myquery.sql:
# -- this is a comment line
# SELECT * -- this is a comment on the same line as SQL
#    -- this is another comment line
#    FROM test
#
# Entries in the queries section may be added or removed freely.
#
# Queries may include a number of optional features in a special nested
# 'features' section underneath the query. Optional features include:
#
# 1. Named parameters using Oracle-style notation.
#    For example, for a file named emp_by_salary.sql containing the query:
#        SELECT * FROM employees e WHERE e.salary > :minimum_salary
#
#    The corresponding configuration would read:
#        [[Find employees by salary]]
#        order = 0
#        sql   = ..\sql\emp_by_salary.sql
#
#            [[[features]]]
#
#                [[[[named_parameters]]]]
#                minimum_salary = 50000
#
# 2. Named parameters using Oracle-style notation where the query is executed
#    once for each set of values in a collection.
#    For example, for a file named emp_by_salary_range.sql containing the query:
#       SELECT ':min - :max' AS range, e.name FROM employees e
#       WHERE e.salary BETWEEN :min AND :max
#
#    The corresponding configuration could read:
#        [[Find employees by salary grouping]]
#        order = 1
#        sql   = ..\sql\emp_by_salary_range.sql
#
#           [[[features]]]
#
#               [[[[multi_named_parameters]]]]
#               keys = min, max
#               value_sets = """[\
#                   [0, 35000], \
#                   [35001, 60000], \
#                   [60001, 1000000], \
#               ]"""
#
# 3. Named parameters using Oracle-style notation using different values on
#    a database-by-database basis. Database names must match the names in the
#    [databases] configuration section.
#    For example, for a file named inv_by_orders.sql containing the query:
#        SELECT * FROM inventory i WHERE i.orders > :min_orders
#
#    The corresponding configuration would read:
#        [[Select inventory by minimum orders]]
#        order = 2
#        sql   = sql\inv_by_orders.sql
#
#            [[[features]]]
#
#                [[[[database_named_parameters]]]]
#
#                    [[[[[db1]]]]]
#                    min_orders = 50
#                    
#                    [[[[[db2]]]]]
#                    min_orders = 100
#
# 4. Templated queries using Python's string substitution. These are queries
#    which require some logic to dynamically generate part of the SQL, as
#    when certain columns must be included in the SELECT statement which are
#    only known at runtime.
#
#    Generating the substitution strings is handled by a user-created Python
#    script which is passed a connection to the current working database. There
#    are no restrictions on what the script may contain, except that it must
#    include the following method as its entry point:
#        getStrings(db)
#    which must return a dictionary of string substitution keys to the string
#    values to replace them with.
#
#    For example, for a file named some_query.sql containing the query:
#        SELECT %(cols)s FROM some_table
#
#    And the substitution script some_template_provider.py containing:
#        def getStrings(db):
#            sql = "SELECT * FROM some_table"
#            cur = db.query(sql)
#
#            stringSubs = {
#                "cols": ", ".join((col for col in cur.getColumns()
#                                   if col.lower().startswith("emp"))}
#
#            return stringSubs
#
#    The corresponding configuration would read:
#        [[Select employee-related columns]]
#        order = 3
#        sql   = sql\some_query.sql
#    
#            [[[features]]]
#
#                [[[[templated]]]]
#                template_provider = sql\some_template_provider.py
#
# 5. Reporting queries. These are ordinary SELECT statements which the
#    MincePy application runs against each configured database, then appends
#    the output to a specified database and table. The output table can be
#    initially dropped by setting the overwrite_reporting_tables flag in the
#    [DEFAULT] section at the top of this file.
#    
#    Note that the query must always return the same columns in the same order
#    for the results to be appended together, so this feature is incompatible
#    with the "templated queries" feature in cases where the columns in the
#    SELECT statement are dynamic.
#
#    The name of the current database can be included in an automatically
#    generated column in the output table by setting the db_title_column to the
#    name of a column to store the current database's title in.
#
#    For example, for a file named simple_inv_by_orders.sql containing the query:
#        SELECT * FROM inventory i WHERE i.orders > 10000
#
#    The corresponding configuration would read:
#        [[Simplified select inventory by minimum orders]]
#        order = 4
#        sql   = r:\queries\simple_inv_by_orders.sql
#
#            [[[features]]]
#
#                [[[[reporting]]]]
#                output_database  = $output_path\Reports.mdb
#                output_table     = inventory_orders
#                db_title_column  = db_title
#                mode             = native # optional
#
#    mode = native uses a faster and more accurate method for moving data from
#    MS Access -> MS Access. If mode is omitted, a more generic method is used.
#
#    Reporting queries can also be written to Excel spreadsheets with these
#    options under the [[[[reporting]]]] heading:
#        file      = <name>.xlsx
#        template  = <template>.xlsx
#        worksheet = <worksheet to insert into>
#        cell      = <top-left cell to begin inserting query results at>
#
#    Output to a PowerPoint template (pptx format) is also supported. This
#    feature copies the template to the specified output file path and fills in
#    the specified shape's text box with the query result. Queries must return a
#    single row with a single column of data.
#        file     = <output file name>.pptx
#        template = <template file name>.pptx
#        slide    = <slide number, starting from 1>
#        shape    = <the name of the shape to write the query result to>
###
    [[Template provider example]]
    order = 1
    sql   = sql\foo_pivot.sql
    
        [[[features]]]
        
            [[[[templated]]]]
            template_provider = sql\template_providers\foo_types.py

    [[Output to Excel]]
    order = 2
    sql   = sql\select_all.sql
    
        [[[features]]]
        
            [[[[named_parameters]]]]
            table = csv_test
            
            [[[[reporting]]]]
            file      = $output_path\reports\Reports.xlsx
            worksheet = csv_test

    [[Output to Excel with template]]
    order = 3
    sql   = sql\select_all.sql
    
        [[[features]]]
        
            [[[[named_parameters]]]]
            table = office_supplies
            
            [[[[reporting]]]]
            file      = $output_path\reports\Templated_Reports.xlsx
            template  = template.xlsx
            worksheet = foo
            cell      = A5

    [[Test data to PowerPoint template - shape 1 of 2]]
    order = 4
    sql   = sql\ppt_shape_1_data.sql
    
        [[[features]]]
        
            [[[[reporting]]]]
            file     = $output_path\reports\PowerPoint_Report.pptx
            template = template.pptx
            slide    = 1
            shape    = Rectangle 4
    
    [[Test data to PowerPoint template - shape 2 of 2]]
    order = 5
    sql   = sql\ppt_shape_2_data.sql
    
        [[[features]]]
        
            [[[[reporting]]]]
            file     = $output_path\reports\PowerPoint_Report.pptx
            template = template.pptx
            slide    = 1
            shape    = Oval 5
